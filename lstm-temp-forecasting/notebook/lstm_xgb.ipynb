{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, LayerNormalization, Add, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adam, AdamW\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from random import choice\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# --- データ準備 ---\n",
    "df = pd.read_csv(\"../datasets/ring_data.csv\")\n",
    "\n",
    "# 特徴量作成（ラグ・移動統計など）\n",
    "df['体温_lag1'] = df['体温'].shift(1)\n",
    "df['室温_lag1'] = df['室温'].shift(1)\n",
    "df['delta_temp'] = df['室温'] - df['体温']\n",
    "df['delta_temp_lag1'] = df['室温_lag1'] - df['体温_lag1']\n",
    "df['体温_ma3'] = df['体温'].rolling(window=3).mean()\n",
    "df['体温_var3'] = df['体温'].rolling(window=3).var()\n",
    "df['室温_ma3'] = df['室温'].rolling(window=3).mean()\n",
    "df['室温_var3'] = df['室温'].rolling(window=3).var()\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 特徴量定義\n",
    "features = [\n",
    "    '体温', '体温_lag1',  '体温_ma3', '体温_var3', \n",
    "    '室温', '室温_lag1',  '室温_ma3', '室温_var3', \n",
    "    'delta_temp', 'delta_temp_lag1',  \n",
    "    'アンケート'\n",
    "]\n",
    "target = '適温'\n",
    "\n",
    "# データ抽出\n",
    "X_raw = df[features].values\n",
    "y_raw = df[[target]].values\n",
    "\n",
    "# ノイズによるデータ拡張\n",
    "noise_std = 0.01 * np.std(X_raw, axis=0)\n",
    "noise = np.random.normal(loc=0.0, scale=noise_std, size=X_raw.shape)\n",
    "X_aug = X_raw + noise\n",
    "y_aug = y_raw.copy()\n",
    "X_combined = np.vstack([X_raw, X_aug])\n",
    "y_combined = np.vstack([y_raw, y_aug])\n",
    "\n",
    "# スケーリング\n",
    "feature_scaler = MinMaxScaler()\n",
    "X_scaled = feature_scaler.fit_transform(X_raw)\n",
    "\n",
    "target_scaler = MinMaxScaler()\n",
    "y_scaled = target_scaler.fit_transform(y_raw)\n",
    "\n",
    "# シーケンス生成関数\n",
    "def create_sequences(X, y, time_steps=3):\n",
    "    n_samples = len(X) - time_steps\n",
    "    X_seq = np.array([X[i:i+time_steps] for i in range(n_samples)])\n",
    "    y_seq = y[time_steps:]\n",
    "    return X_seq, y_seq\n",
    "\n",
    "# シーケンス生成\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps = 3)\n",
    "\n",
    "# データ分割（shuffle=False）\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False, random_state=42)\n",
    "\n",
    "# --- LSTM モデル学習 ---\n",
    "epochs_list = [60, 90, 120]\n",
    "batch_sizes = [4, 8, 16]\n",
    "lstm_units = [60, 90, 120]\n",
    "dropout_rates = [0.001, 0.01, 0.05]\n",
    "l2_reg_strengths = [0.01, 0.1, 0.2]\n",
    "best_loss = float('inf')\n",
    "best_model = None\n",
    "\n",
    "for _ in range(15):\n",
    "    epochs = choice(epochs_list)\n",
    "    batch_size = choice(batch_sizes)\n",
    "    units = choice(lstm_units)\n",
    "    dropout = choice(dropout_rates)\n",
    "    l2_reg_strength = choice(l2_reg_strengths)\n",
    "\n",
    "    input_layer = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    x = Bidirectional(LSTM(units, return_sequences=True, kernel_regularizer=l2(l2_reg_strength)))(input_layer)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Bidirectional(LSTM(units // 2, return_sequences=False, kernel_regularizer=l2(l2_reg_strength)))(x)\n",
    "    x = LayerNormalization()(x)\n",
    "\n",
    "    residual = x\n",
    "    residual_units = K.int_shape(residual)[-1]\n",
    "    x = Dense(residual_units, activation='gelu', kernel_regularizer=l2(l2_reg_strength))(x)\n",
    "    x = Add()([x, residual])\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "\n",
    "    output = Dense(1)(x)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer=AdamW(learning_rate=1e-3, weight_decay=1e-5), loss='mse')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=0)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model = model\n",
    "        best_history = history  # ← ここで保存\n",
    "\n",
    "# --- LSTM特徴抽出 ---\n",
    "feature_extractor = Model(inputs=best_model.input, outputs=best_model.layers[-3].output)\n",
    "X_train_lstm_feat = feature_extractor.predict(X_train)\n",
    "X_test_lstm_feat = feature_extractor.predict(X_test)\n",
    "\n",
    "# --- XGBoost用に元データと同期 ---\n",
    "time_steps = 3\n",
    "X_raw_cut = X_raw[time_steps:]\n",
    "y_raw_cut = y_raw[time_steps:]\n",
    "X_train_static = X_raw_cut[:len(X_train)]\n",
    "X_test_static = X_raw_cut[-len(X_test):]\n",
    "X_train_combined = np.hstack([X_train_static, X_train_lstm_feat])\n",
    "X_test_combined = np.hstack([X_test_static, X_test_lstm_feat])\n",
    "\n",
    "# --- XGBoost 学習・予測 ---\n",
    "xgb_model = XGBRegressor(n_estimators=100, max_depth=4, learning_rate=0.05, random_state=42)\n",
    "xgb_model.fit(X_train_combined, y_train)\n",
    "\n",
    "xgb_preds = xgb_model.predict(X_test_combined)\n",
    "xgb_preds_inv = target_scaler.inverse_transform(xgb_preds.reshape(-1, 1)).flatten()\n",
    "actual_temps_inv = target_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e079db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 精度指標計算\n",
    "mse = mean_squared_error(actual_temps_inv, xgb_preds_inv)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(actual_temps_inv, xgb_preds_inv)\n",
    "r2 = r2_score(actual_temps_inv, xgb_preds_inv)\n",
    "\n",
    "print(f\"XGBoost Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"XGBoost Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"XGBoost Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"XGBoost R^2 Score: {r2:.4f}\")\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.2)\n",
    "\n",
    "# --- LSTMのトレーニングと検証損失推移 ---\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.lineplot(data=best_history.history['loss'], label='トレーニング損失', color='royalblue', linewidth=2)\n",
    "sns.lineplot(data=best_history.history['val_loss'], label='検証損失', color='tomato', linewidth=2)\n",
    "plt.title('トレーニングと検証の損失推移')\n",
    "plt.xlabel('エポック')\n",
    "plt.ylabel('損失 (MSE)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- ハイブリッドモデル予測と実測の適温推移グラフ ---\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.lineplot(x=range(len(xgb_preds_inv)), y=xgb_preds_inv, label='ハイブリッドモデル予測適温', color='royalblue', linewidth=2)\n",
    "sns.lineplot(x=range(len(actual_temps_inv)), y=actual_temps_inv, label='実際の適温', color='tomato', linestyle='--', linewidth=2)\n",
    "plt.title('ハイブリッドモデル予測適温と実際の適温の比較')\n",
    "plt.xlabel('時間ステップ')\n",
    "plt.ylabel('温度 (℃)')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c012b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# 評価指標を辞書でまとめる\n",
    "results_dict = {\n",
    "    \"MSE\": [mse],\n",
    "    \"RMSE\": [rmse],\n",
    "    \"MAE\": [mae],\n",
    "    \"R2\": [r2]\n",
    "}\n",
    "\n",
    "# DataFrameに変換\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "# 保存先ディレクトリ\n",
    "results_dir = \"../results\"\n",
    "os.makedirs(results_dir, exist_ok=True)  # フォルダがなければ作成\n",
    "\n",
    "# 保存ファイル名\n",
    "filename = \"ring_lstm_xgb.csv\"  \n",
    "\n",
    "# フルパスを作成\n",
    "filepath = os.path.join(results_dir, filename)\n",
    "\n",
    "# CSV保存（indexは不要）\n",
    "results_df.to_csv(filepath, index=False)\n",
    "\n",
    "print(f\"評価結果を保存しました: {filepath}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
